const express = require("express");
const cors = require("cors");
const axios = require("axios");
const dotenv = require("dotenv");

// ðŸ” Load biáº¿n mÃ´i trÆ°á»ng tá»« .env
dotenv.config();

const app = express();
const PORT = process.env.PORT || 3000;

// ðŸ” Cho phÃ©p cÃ¡c request tá»« trÃ¬nh duyá»‡t
app.use(cors());
app.use(express.json());

// ðŸ“‚ Phá»¥c vá»¥ file tÄ©nh trong thÆ° má»¥c "public"
app.use(express.static("public"));

// ðŸ” Endpoint Ä‘á»ƒ proxy yÃªu cáº§u tá»« client Ä‘áº¿n OpenAI
app.post("/v1/responses", async (req, res) => {
  const { input, model } = req.body;

  try {
    const response = await axios.post(
      "https://api.openai.com/v1/chat/completions",
      {
        model: model || "gpt-3.5-turbo",
        messages: input,
        temperature: 0.7,
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
          "Content-Type": "application/json",
        },
      }
    );

    const output = response.data.choices.map((choice) => ({
      content: [{ text: choice.message.content }],
    }));

    res.json({ output });
  } catch (error) {
    console.error("âŒ Lá»—i proxy:", error.response?.data || error.message);
    res.status(error.response?.status || 500).json({
      error: "Lá»—i khi gá»i API OpenAI",
      details: error.response?.data || error.message,
    });
  }
});

// ðŸš€ Báº¯t Ä‘áº§u server
app.listen(PORT, () => {
  console.log(`âœ… Proxy Ä‘ang cháº¡y táº¡i http://localhost:${PORT}/v1/responses`);
});
